<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>History page</title>
    <link rel="stylesheet" href="CSS-folder/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Kanit:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
        rel="stylesheet">
</head>

<body>
    <!-- ---------------------NAV MENU-------------------- ---------->
    <nav>
        <ul>
            <li><a class="pages" href="index.html">Home</a></li>
            <li><a class="pages" href="OperatingSystems.html">OperatingSystems</a></li>
            <li><a class="pages" href="history.html">History</a></li>
            <li><a class="pages" href="contact.html">Contact</a></li>
            <!-- -------------------Text Box--------------------------- -->
        </ul>
    </nav>
    <header id="history-header">The History of Computers</header>
    <main class="history-main">
        <div class="flex-container">
            <p class="history-p">The history of computer progress is a great human and technological story that took
                centuries. This started with ancient people like Babylonians and Egyptians who thought up computing
                devices, for example, calculating tools such as abacus and Antikythera mechanism. These primitive
                gadgets were then developed into more advanced computational tools; notable among these was Charles
                Babbage’s mechanical calculators like the Difference Engine and Analytical Engine that introduced
                concepts of programmability, stored memory and others.
                The 20th century witnessed some remarkable breakthroughs which marked the modern age of computing. The
                Second World War saw the invention of electronic computers such as Colossus and ENIAC that provided fast
                computations for military purposes and scientific research. With the war over, Bell Labs researchers
                discovered transistor technology in the 1950s leading to an era characterized by miniaturization as well
                as efficiency hence making it essential in creating smaller, faster and more reliable computers.The
                1970s saw the personal computer revolution,
                with the introduction of devices such as the Altair 8800 and the Apple I, which enabled individuals and
                small businesses to work on computers for the first time. They played a major role in the formation of
                the future of computers and then the development of integrated circuit technology which is one of the
                decades, the development of machines and internets in computing power, a power deskot, laptopphonas, .
                others, Digital devices that expand inevitably Built in modern life. Today, the relentless progress
                continues with advances in areas such as quantum computing,
                artificial intelligence and edge computing, which promise to redefine the boundaries of what’s possible
                in computing
            </p>
        </div>
        <!-- ---------------TimeLine Table----------------------- -->
        <table class="history-table">
            <caption>Key Milestones in the History of Computing</caption>
            <thead>
                <tr>
                    <th>Year</th>
                    <th>Event</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>1837</td>
                    <td>Charles Babbage designs the Analytical Engine, considered the first mechanical computer</td>
                </tr>
                <tr>
                    <td>1947</td>
                    <td>Invention of the transistor at Bell Labs, revolutionizing electronics and paving the way for
                        modern computers</td>
                </tr>
                <tr>
                    <td>1948</td>
                    <td>Claude Shannon publishes "A Mathematical Theory of Communication", laying the groundwork for
                        information theory and digital circuit design</td>
                </tr>
                <tr>
                    <td>1958</td>
                    <td>Jack Kilby invents the integrated circuit (IC), revolutionizing electronic computing by packing
                        multiple components onto a single chip</td>
                </tr>
                <tr>
                    <td>1969</td>
                    <td>ARPANET, the precursor to the internet, is established by the Advanced Research Projects Agency
                        (ARPA)</td>
                </tr>
                <tr>
                    <td>1971</td>
                    <td>Intel introduces the first microprocessor, the 4004, sparking the development of personal
                        computers</td>
                </tr>
                <tr>
                    <td>1989</td>
                    <td>Tim Berners-Lee invents the World Wide Web, revolutionizing the way information is shared and
                        accessed</td>
                </tr>
                <tr>
                    <td>1991</td>
                    <td>Linus Torvalds releases the Linux kernel, paving the way for the open-source software movement
                    </td>
                </tr>
                <tr>
                    <td>2007</td>
                    <td>Apple releases the iPhone, popularizing smartphones and mobile computing</td>
                </tr>
                <!-- will Add more rows as needed -->
            </tbody>
        </table>
    </main>
    <footer id="history-footer">Austin Fitzhugh. 1/22/2024</footer>
</body>

</html>